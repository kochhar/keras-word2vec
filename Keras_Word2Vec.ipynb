{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kochhar/keras-word2vec/blob/master/Keras_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "m_rbaQARKBDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4d23a2f4-c53f-4e66-9645-0a23276de4c6"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kochhar/keras-word2vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-word2vec'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/45)   \u001b[K\rremote: Counting objects:   4% (2/45)   \u001b[K\rremote: Counting objects:   6% (3/45)   \u001b[K\rremote: Counting objects:   8% (4/45)   \u001b[K\rremote: Counting objects:  11% (5/45)   \u001b[K\rremote: Counting objects:  13% (6/45)   \u001b[K\rremote: Counting objects:  15% (7/45)   \u001b[K\rremote: Counting objects:  17% (8/45)   \u001b[K\rremote: Counting objects:  20% (9/45)   \u001b[K\rremote: Counting objects:  22% (10/45)   \u001b[K\rremote: Counting objects:  24% (11/45)   \u001b[K\rremote: Counting objects:  26% (12/45)   \u001b[K\rremote: Counting objects:  28% (13/45)   \u001b[K\rremote: Counting objects:  31% (14/45)   \u001b[K\rremote: Counting objects:  33% (15/45)   \u001b[K\rremote: Counting objects:  35% (16/45)   \u001b[K\rremote: Counting objects:  37% (17/45)   \u001b[K\rremote: Counting objects:  40% (18/45)   \u001b[K\rremote: Counting objects:  42% (19/45)   \u001b[K\rremote: Counting objects:  44% (20/45)   \u001b[K\rremote: Counting objects:  46% (21/45)   \u001b[K\rremote: Counting objects:  48% (22/45)   \u001b[K\rremote: Counting objects:  51% (23/45)   \u001b[K\rremote: Counting objects:  53% (24/45)   \u001b[K\rremote: Counting objects:  55% (25/45)   \u001b[K\rremote: Counting objects:  57% (26/45)   \u001b[K\rremote: Counting objects:  60% (27/45)   \u001b[K\rremote: Counting objects:  62% (28/45)   \u001b[K\rremote: Counting objects:  64% (29/45)   \u001b[K\rremote: Counting objects:  66% (30/45)   \u001b[K\rremote: Counting objects:  68% (31/45)   \u001b[K\rremote: Counting objects:  71% (32/45)   \u001b[K\rremote: Counting objects:  73% (33/45)   \u001b[K\rremote: Counting objects:  75% (34/45)   \u001b[K\rremote: Counting objects:  77% (35/45)   \u001b[K\rremote: Counting objects:  80% (36/45)   \u001b[K\rremote: Counting objects:  82% (37/45)   \u001b[K\rremote: Counting objects:  84% (38/45)   \u001b[K\rremote: Counting objects:  86% (39/45)   \u001b[K\rremote: Counting objects:  88% (40/45)   \u001b[K\rremote: Counting objects:  91% (41/45)   \u001b[K\rremote: Counting objects:  93% (42/45)   \u001b[K\rremote: Counting objects:  95% (43/45)   \u001b[K\rremote: Counting objects:  97% (44/45)   \u001b[K\rremote: Counting objects: 100% (45/45)   \u001b[K\rremote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/25)   \u001b[K\rremote: Compressing objects:   8% (2/25)   \u001b[K\rremote: Compressing objects:  12% (3/25)   \u001b[K\rremote: Compressing objects:  16% (4/25)   \u001b[K\rremote: Compressing objects:  20% (5/25)   \u001b[K\rremote: Compressing objects:  24% (6/25)   \u001b[K\rremote: Compressing objects:  28% (7/25)   \u001b[K\rremote: Compressing objects:  32% (8/25)   \u001b[K\rremote: Compressing objects:  36% (9/25)   \u001b[K\rremote: Compressing objects:  40% (10/25)   \u001b[K\rremote: Compressing objects:  44% (11/25)   \u001b[K\rremote: Compressing objects:  48% (12/25)   \u001b[K\rremote: Compressing objects:  52% (13/25)   \u001b[K\rremote: Compressing objects:  56% (14/25)   \u001b[K\rremote: Compressing objects:  60% (15/25)   \u001b[K\rremote: Compressing objects:  64% (16/25)   \u001b[K\rremote: Compressing objects:  68% (17/25)   \u001b[K\rremote: Compressing objects:  72% (18/25)   \u001b[K\rremote: Compressing objects:  76% (19/25)   \u001b[K\rremote: Compressing objects:  80% (20/25)   \u001b[K\rremote: Compressing objects:  84% (21/25)   \u001b[K\rremote: Compressing objects:  88% (22/25)   \u001b[K\rremote: Compressing objects:  92% (23/25)   \u001b[K\rremote: Compressing objects:  96% (24/25)   \u001b[K\rremote: Compressing objects: 100% (25/25)   \u001b[K\rremote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 45 (delta 17), reused 36 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nBgfNh41h6Lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41cd1789-8985-4c68-c3e3-d882870de379"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/keras-word2vec')\n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/keras-word2vec'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "PQ14GMrGm-IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c06312ea-9f5f-45eb-8793-9d8827d39f16"
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)   \u001b[K\rremote: Counting objects:  28% (2/7)   \u001b[K\rremote: Counting objects:  42% (3/7)   \u001b[K\rremote: Counting objects:  57% (4/7)   \u001b[K\rremote: Counting objects:  71% (5/7)   \u001b[K\rremote: Counting objects:  85% (6/7)   \u001b[K\rremote: Counting objects: 100% (7/7)   \u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)   \u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "From https://github.com/kochhar/keras-word2vec\n",
            "   50e51cf..13fe8f4  master     -> origin/master\n",
            "Updating 50e51cf..13fe8f4\n",
            "Fast-forward\n",
            " word2vec/__init__.py | 12 \u001b[32m++++\u001b[m\u001b[31m--------\u001b[m\n",
            " 1 file changed, 4 insertions(+), 8 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQ6x01cQh-Y2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dda05ce3-9efe-435c-ccb5-55c67643d22f"
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import logging\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import word2vec as w2v\n",
        "from importlib import reload\n",
        "w2v = reload(w2v)\n",
        "\n",
        "logging.basicConfig(format=\"[%(asctime)s]%(levelname)s:%(name)s:%(message)s\",\n",
        "                    level=logging.INFO)\n",
        "logging.info('logging configured')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2018-10-30 03:26:30,161]INFO:root:logging configured\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R2Ngk61PiH7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "91b665bf-12cc-45bf-c977-b23f95e7b1f2"
      },
      "cell_type": "code",
      "source": [
        "filename = 'data/text8.zip'\n",
        "logging.info('Reading corpus')\n",
        "training_corpus = w2v.str_from_zipfile(filename).split()\n",
        "logging.info('Corpus: %s words', len(training_corpus))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2018-10-30 03:07:14,666]INFO:root:Reading corpus\n",
            "[2018-10-30 03:07:16,853]INFO:root:Corpus: 17005207 words\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YJqHZUKcih6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "dc6d23ec-db33-41c4-962c-b39d0cd2dc28"
      },
      "cell_type": "code",
      "source": [
        "logging.info('Creating vocabulary')\n",
        "counts = [('UNK', -1)] + collections.Counter(training_corpus).most_common(int(1e4-1))\n",
        "vocab = w2v.Vocabulary([word for (word, _) in counts ])\n",
        "logging.info('Encoding corpus')\n",
        "tokens = vocab.encode(training_corpus)\n",
        "logging.info(\"Vocab: %s tokens, Sample: %s\", vocab.size, list(zip(training_corpus[:7], tokens[:7])))\n",
        "del training_corpus\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2018-10-30 03:07:20,751]INFO:root:Creating vocabulary\n",
            "[2018-10-30 03:07:24,523]INFO:root:Encoding corpus\n",
            "[2018-10-30 03:07:27,941]INFO:root:Vocab: 10000 tokens, Sample: [('anarchism', 5234), ('originated', 3081), ('as', 12), ('a', 6), ('term', 195), ('of', 2), ('abuse', 3134)]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EpZLaYIfjut9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5a526517-a8c5-405f-9a70-3094d33c88af"
      },
      "cell_type": "code",
      "source": [
        "logging.info('Creating skipgrams')\n",
        "word_target, word_context, labels = sgns.skipgrams(tokens, window_size=3)\n",
        "logging.info('Training skipgrams: %s, Sample: %s', len(word_target), \n",
        "             list(zip(word_target[:10], word_context[:10], labels[:10])))\n",
        "del tokens"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2018-10-30 03:07:38,411]INFO:root:Creating skipgrams\n",
            "[2018-10-30 03:12:05,531]INFO:root:Training skipgrams: 30022202, Sample: [(9817, 3, 1), (1460, 1264, 0), (6786, 831, 0), (6777, 7884, 0), (278, 990, 0), (606, 6433, 0), (5230, 8627, 0), (669, 9626, 0), (1057, 1614, 0), (2831, 4311, 0)]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfCPTr2EBm71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Similarity(object):\n",
        "    def __init__(self, sim_model):\n",
        "        \"\"\"Params:\n",
        "            - sim_model: A keras model which outputs a similarity score given\n",
        "              two vectors as inputs\"\"\"\n",
        "        self.sim_model = sim_model\n",
        "\n",
        "    def most_similar(self, examples, vocab, top_k=10):\n",
        "        sim_fn = self.sim\n",
        "        contexts = range(vocab.size)\n",
        "        # compute the similarity between the example and every context word in the vocabulary\n",
        "        sims = [(ex, sim_fn(ex, contexts)) for ex in examples]\n",
        "        sims = [(ex, (-sim).argsort()[1:top_k+1], sim) for (ex, sim) in sims]\n",
        "        return [(ex, top_idx, sim[top_idx]) for (ex, top_idx, sim) in sims]\n",
        "\n",
        "    def sim(self, target, contexts):\n",
        "        context_b = np.array(contexts)\n",
        "        # the target word for every item in the batch is the same\n",
        "        target_b = np.array([target]*len(contexts))\n",
        "        sim_b = self.sim_model.predict_on_batch([target_b, context_b])\n",
        "        \n",
        "        # reshape from (len(contexts), 1) to (len(contexts),)\n",
        "        sim_b = sim_b.reshape(context_b.shape)\n",
        "        return sim_b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPY4gYV1n4Nk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5612
        },
        "outputId": "1a30b5f0-e1f5-4b9a-e346-c7aedf44bc85"
      },
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "sgns = w2v.SkipGramNegSample(vocab_size=vocab.size, embedding_dim=300)\n",
        "model, validation_model = sgns.model()\n",
        "sim_eval = Similarity(validation_model)\n",
        "\n",
        "# Validation set for inspecting training progress\n",
        "# Max index of the random sampling from tokens (implies choosing\n",
        "# from the the top-N occurring tokens)\n",
        "max_token_idx = 128\n",
        "valid_samples = np.random.choice(np.arange(24, max_token_idx), size=16, replace=False)\n",
        "\n",
        "# Feeding to the network\n",
        "batch_size, offset = 128, 127\n",
        "tgt_b, ctx_b, lbl_b = np.zeros((batch_size,)), np.zeros((batch_size,)), np.zeros((batch_size,))\n",
        "# training loop over 1e6 epochs with batches of size 32\n",
        "for epoch in range(5):\n",
        "  for idx in range(0, len(word_target), batch_size):\n",
        "      tgt_b[0:offset,] = word_target[idx:idx+offset]\n",
        "      ctx_b[0:offset,] = word_context[cnt:cnt+offset]\n",
        "      lbl_b[0:offset,] = labels[cnt:cnt+offset]\n",
        "      loss = model.train_on_batch([tgt_b, ctx_b], lbl_b)\n",
        "\n",
        "      if idx % 51200 == 0:\n",
        "          logging.info(\"Epoch: %s, Iteration %s, loss=%s\", epoch, idx, loss)\n",
        "      if idx % 1024000 == 0:\n",
        "          most_similar = sim_eval.most_similar(valid_samples, vocab)\n",
        "          log_str = '\\n'+'\\n'.join(['Nearest to {}: {}, Median sim: {:.3}'\n",
        "                                       .format(vocab.decode([ex]), ', '.join(vocab.decode(top_idx)), scores[4])\n",
        "                                   for (ex, top_idx, scores) in most_similar])\n",
        "          logging.info(log_str)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2018-10-30 04:49:06,875]INFO:root:Epoch: 0, Iteration 0, loss=0.6931793\n",
            "[2018-10-30 04:49:07,258]INFO:root:\n",
            "Nearest to ['english']: bandwidth, dinner, decorated, unclear, cool, concerned, instability, denominations, cambodia, center, Median sim: 0.195\n",
            "Nearest to ['under']: peirce, approach, matters, potential, aware, classes, causing, mason, oct, dundee, Median sim: 0.186\n",
            "Nearest to ['some']: seats, automatic, media, car, mickey, focused, joey, offence, persecution, magic, Median sim: 0.195\n",
            "Nearest to ['were']: surrendered, program, suffix, branch, conferences, westminster, consumed, division, object, small, Median sim: 0.189\n",
            "Nearest to ['united']: stomach, der, fred, carnegie, drops, pleasant, qquad, par, revision, end, Median sim: 0.183\n",
            "Nearest to ['e']: capital, penis, programme, established, tribune, emissions, sculpture, goddess, champions, vowel, Median sim: 0.184\n",
            "Nearest to ['be']: torah, folk, touch, assert, arrives, begin, programmes, richard, vehicles, fl, Median sim: 0.201\n",
            "Nearest to ['his']: elves, crick, requires, j, despite, mach, colonel, wounds, educated, allah, Median sim: 0.184\n",
            "Nearest to ['b']: batman, verde, variations, mount, observed, neighboring, google, br, throws, focused, Median sim: 0.177\n",
            "Nearest to ['if']: discuss, maxwell, flaws, attend, liverpool, leto, reserve, infinitive, east, conditioning, Median sim: 0.177\n",
            "Nearest to ['over']: violent, confirmed, neo, nose, junta, request, occurrence, organizations, elephant, topology, Median sim: 0.185\n",
            "Nearest to ['when']: achieved, peaks, magical, am, walt, capitalist, handheld, kabbalah, album, congress, Median sim: 0.199\n",
            "Nearest to ['x']: unification, harpsichord, talking, necessity, fl, barnabas, bride, blank, impression, paint, Median sim: 0.189\n",
            "Nearest to ['time']: collect, mathematicians, associations, regard, col, acronym, hebrew, laboratories, file, ivoire, Median sim: 0.199\n",
            "Nearest to ['since']: nights, internationally, historically, amounts, graduate, participating, nicaragua, them, extensive, range, Median sim: 0.188\n",
            "Nearest to ['will']: te, micro, identities, differs, chris, huge, motorcycles, raids, oz, boat, Median sim: 0.188\n",
            "[2018-10-30 04:49:10,415]INFO:root:Epoch: 0, Iteration 51200, loss=0.6840763\n",
            "[2018-10-30 04:49:13,538]INFO:root:Epoch: 0, Iteration 102400, loss=0.5473539\n",
            "[2018-10-30 04:49:16,651]INFO:root:Epoch: 0, Iteration 153600, loss=0.1876512\n",
            "[2018-10-30 04:49:19,798]INFO:root:Epoch: 0, Iteration 204800, loss=0.17632414\n",
            "[2018-10-30 04:49:22,934]INFO:root:Epoch: 0, Iteration 256000, loss=0.06052292\n",
            "[2018-10-30 04:49:26,152]INFO:root:Epoch: 0, Iteration 307200, loss=0.5738366\n",
            "[2018-10-30 04:49:29,409]INFO:root:Epoch: 0, Iteration 358400, loss=0.17215522\n",
            "[2018-10-30 04:49:32,632]INFO:root:Epoch: 0, Iteration 409600, loss=0.14194179\n",
            "[2018-10-30 04:49:35,851]INFO:root:Epoch: 0, Iteration 460800, loss=0.35113415\n",
            "[2018-10-30 04:49:39,139]INFO:root:Epoch: 0, Iteration 512000, loss=0.15105677\n",
            "[2018-10-30 04:49:42,396]INFO:root:Epoch: 0, Iteration 563200, loss=0.07894562\n",
            "[2018-10-30 04:49:45,638]INFO:root:Epoch: 0, Iteration 614400, loss=0.2906715\n",
            "[2018-10-30 04:49:48,936]INFO:root:Epoch: 0, Iteration 665600, loss=0.17604987\n",
            "[2018-10-30 04:49:52,217]INFO:root:Epoch: 0, Iteration 716800, loss=0.12969518\n",
            "[2018-10-30 04:49:55,446]INFO:root:Epoch: 0, Iteration 768000, loss=0.0030197946\n",
            "[2018-10-30 04:49:58,732]INFO:root:Epoch: 0, Iteration 819200, loss=0.0037019053\n",
            "[2018-10-30 04:50:01,966]INFO:root:Epoch: 0, Iteration 870400, loss=0.0025266465\n",
            "[2018-10-30 04:50:05,192]INFO:root:Epoch: 0, Iteration 921600, loss=0.21307686\n",
            "[2018-10-30 04:50:08,407]INFO:root:Epoch: 0, Iteration 972800, loss=0.0031212927\n",
            "[2018-10-30 04:50:11,595]INFO:root:Epoch: 0, Iteration 1024000, loss=0.00178441\n",
            "[2018-10-30 04:50:11,710]INFO:root:\n",
            "Nearest to ['english']: nine, four, are, s, on, their, a, from, church, five, Median sim: 0.946\n",
            "Nearest to ['under']: which, with, are, s, has, four, all, it, air, u, Median sim: 0.954\n",
            "Nearest to ['some']: with, four, a, s, six, nine, has, five, on, are, Median sim: 0.963\n",
            "Nearest to ['were']: are, which, on, four, he, s, american, nine, be, seven, Median sim: 0.966\n",
            "Nearest to ['united']: s, four, with, which, six, on, a, nine, has, his, Median sim: 0.956\n",
            "Nearest to ['e']: five, six, s, four, seven, a, american, on, three, nine, Median sim: 0.951\n",
            "Nearest to ['be']: on, s, a, nine, four, are, six, seven, five, three, Median sim: 0.971\n",
            "Nearest to ['his']: three, a, six, nine, has, he, s, with, are, which, Median sim: 0.969\n",
            "Nearest to ['b']: armored, right, prime, dominant, though, computers, indonesia, hebrew, different, mhz, Median sim: 0.977\n",
            "Nearest to ['if']: nine, this, six, seven, which, are, five, with, s, from, Median sim: 0.963\n",
            "Nearest to ['over']: four, a, nine, six, has, five, seven, after, s, are, Median sim: 0.958\n",
            "Nearest to ['when']: been, they, an, would, at, as, or, use, eight, is, Median sim: 0.703\n",
            "Nearest to ['x']: s, four, seven, five, a, had, after, nine, has, there, Median sim: 0.957\n",
            "Nearest to ['time']: s, nine, four, a, has, it, seven, he, which, not, Median sim: 0.965\n",
            "Nearest to ['since']: nine, from, four, which, are, first, on, seven, six, after, Median sim: 0.953\n",
            "Nearest to ['will']: has, s, a, which, himself, after, are, four, on, it, Median sim: 0.956\n",
            "[2018-10-30 04:50:14,941]INFO:root:Epoch: 0, Iteration 1075200, loss=0.12711151\n",
            "[2018-10-30 04:50:18,098]INFO:root:Epoch: 0, Iteration 1126400, loss=0.0009818049\n",
            "[2018-10-30 04:50:21,303]INFO:root:Epoch: 0, Iteration 1177600, loss=0.12663257\n",
            "[2018-10-30 04:50:24,512]INFO:root:Epoch: 0, Iteration 1228800, loss=0.0005880144\n",
            "[2018-10-30 04:50:27,702]INFO:root:Epoch: 0, Iteration 1280000, loss=0.023306392\n",
            "[2018-10-30 04:50:30,977]INFO:root:Epoch: 0, Iteration 1331200, loss=0.15179935\n",
            "[2018-10-30 04:50:34,337]INFO:root:Epoch: 0, Iteration 1382400, loss=0.008298876\n",
            "[2018-10-30 04:50:37,657]INFO:root:Epoch: 0, Iteration 1433600, loss=0.0020598266\n",
            "[2018-10-30 04:50:40,872]INFO:root:Epoch: 0, Iteration 1484800, loss=0.12620372\n",
            "[2018-10-30 04:50:44,064]INFO:root:Epoch: 0, Iteration 1536000, loss=0.0005242872\n",
            "[2018-10-30 04:50:47,379]INFO:root:Epoch: 0, Iteration 1587200, loss=0.040540315\n",
            "[2018-10-30 04:50:50,667]INFO:root:Epoch: 0, Iteration 1638400, loss=0.12571406\n",
            "[2018-10-30 04:50:53,933]INFO:root:Epoch: 0, Iteration 1689600, loss=0.00097219273\n",
            "[2018-10-30 04:50:57,236]INFO:root:Epoch: 0, Iteration 1740800, loss=0.028311377\n",
            "[2018-10-30 04:51:00,564]INFO:root:Epoch: 0, Iteration 1792000, loss=0.005965487\n",
            "[2018-10-30 04:51:03,919]INFO:root:Epoch: 0, Iteration 1843200, loss=0.0042600506\n",
            "[2018-10-30 04:51:07,244]INFO:root:Epoch: 0, Iteration 1894400, loss=0.24941124\n",
            "[2018-10-30 04:51:10,539]INFO:root:Epoch: 0, Iteration 1945600, loss=0.016744148\n",
            "[2018-10-30 04:51:13,859]INFO:root:Epoch: 0, Iteration 1996800, loss=0.0018092107\n",
            "[2018-10-30 04:51:17,202]INFO:root:Epoch: 0, Iteration 2048000, loss=0.00059751404\n",
            "[2018-10-30 04:51:17,325]INFO:root:\n",
            "Nearest to ['english']: known, around, information, church, since, their, i, within, order, another, Median sim: 0.971\n",
            "Nearest to ['under']: around, still, all, air, u, if, several, list, language, after, Median sim: 0.976\n",
            "Nearest to ['some']: with, between, time, has, d, first, into, because, there, all, Median sim: 0.976\n",
            "Nearest to ['were']: american, are, first, which, there, because, into, can, on, all, Median sim: 0.977\n",
            "Nearest to ['united']: were, first, those, which, where, its, their, has, over, american, Median sim: 0.975\n",
            "Nearest to ['e']: capital, area, high, over, david, study, using, where, person, series, Median sim: 0.972\n",
            "Nearest to ['be']: on, s, a, are, four, seven, six, nine, from, three, Median sim: 0.98\n",
            "Nearest to ['his']: three, a, has, s, he, six, with, it, are, which, Median sim: 0.978\n",
            "Nearest to ['b']: armored, right, prime, mhz, dominant, hebrew, though, different, such, indonesia, Median sim: 0.984\n",
            "Nearest to ['if']: under, part, information, other, year, high, most, way, example, game, Median sim: 0.975\n",
            "Nearest to ['over']: after, british, within, i, number, game, used, because, based, about, Median sim: 0.977\n",
            "Nearest to ['when']: who, would, an, they, at, as, been, or, use, eight, Median sim: 0.862\n",
            "Nearest to ['x']: before, after, now, game, life, there, several, government, information, known, Median sim: 0.975\n",
            "Nearest to ['time']: there, has, s, had, first, other, between, it, four, some, Median sim: 0.978\n",
            "Nearest to ['since']: after, number, order, usually, first, i, states, information, another, new, Median sim: 0.975\n",
            "Nearest to ['will']: himself, red, still, family, several, after, cases, new, under, languages, Median sim: 0.975\n",
            "[2018-10-30 04:51:20,664]INFO:root:Epoch: 0, Iteration 2099200, loss=0.0012756791\n",
            "[2018-10-30 04:51:24,013]INFO:root:Epoch: 0, Iteration 2150400, loss=0.0014054504\n",
            "[2018-10-30 04:51:27,327]INFO:root:Epoch: 0, Iteration 2201600, loss=0.0013407584\n",
            "[2018-10-30 04:51:30,549]INFO:root:Epoch: 0, Iteration 2252800, loss=0.00085548987\n",
            "[2018-10-30 04:51:33,815]INFO:root:Epoch: 0, Iteration 2304000, loss=0.020518817\n",
            "[2018-10-30 04:51:37,150]INFO:root:Epoch: 0, Iteration 2355200, loss=0.012253894\n",
            "[2018-10-30 04:51:40,490]INFO:root:Epoch: 0, Iteration 2406400, loss=0.0010807868\n",
            "[2018-10-30 04:51:43,791]INFO:root:Epoch: 0, Iteration 2457600, loss=0.002559043\n",
            "[2018-10-30 04:51:47,103]INFO:root:Epoch: 0, Iteration 2508800, loss=0.12574983\n",
            "[2018-10-30 04:51:50,452]INFO:root:Epoch: 0, Iteration 2560000, loss=0.011196571\n",
            "[2018-10-30 04:51:53,573]INFO:root:Epoch: 0, Iteration 2611200, loss=0.0025246413\n",
            "[2018-10-30 04:51:56,681]INFO:root:Epoch: 0, Iteration 2662400, loss=0.00065869\n",
            "[2018-10-30 04:51:59,766]INFO:root:Epoch: 0, Iteration 2713600, loss=0.009701268\n",
            "[2018-10-30 04:52:02,942]INFO:root:Epoch: 0, Iteration 2764800, loss=0.009535693\n",
            "[2018-10-30 04:52:06,272]INFO:root:Epoch: 0, Iteration 2816000, loss=0.0011084338\n",
            "[2018-10-30 04:52:09,420]INFO:root:Epoch: 0, Iteration 2867200, loss=0.0030529068\n",
            "[2018-10-30 04:52:12,783]INFO:root:Epoch: 0, Iteration 2918400, loss=0.00091094105\n",
            "[2018-10-30 04:52:16,169]INFO:root:Epoch: 0, Iteration 2969600, loss=0.27198708\n",
            "[2018-10-30 04:52:19,585]INFO:root:Epoch: 0, Iteration 3020800, loss=0.00089005637\n",
            "[2018-10-30 04:52:22,823]INFO:root:Epoch: 0, Iteration 3072000, loss=0.003087196\n",
            "[2018-10-30 04:52:22,945]INFO:root:\n",
            "Nearest to ['english']: known, around, information, since, another, within, m, century, order, company, Median sim: 0.985\n",
            "Nearest to ['under']: around, still, several, list, man, those, available, language, power, if, Median sim: 0.988\n",
            "Nearest to ['some']: first, there, has, new, time, other, had, can, its, all, Median sim: 0.987\n",
            "Nearest to ['were']: first, there, american, most, other, after, new, some, can, used, Median sim: 0.987\n",
            "Nearest to ['united']: those, where, music, him, countries, name, you, if, national, over, Median sim: 0.987\n",
            "Nearest to ['e']: using, study, area, high, western, capital, person, series, old, long, Median sim: 0.987\n",
            "Nearest to ['be']: s, on, are, from, seven, four, he, three, it, five, Median sim: 0.989\n",
            "Nearest to ['his']: three, he, not, it, s, has, are, from, which, this, Median sim: 0.988\n",
            "Nearest to ['b']: though, different, computers, prime, mhz, flying, such, hebrew, armored, paul, Median sim: 0.968\n",
            "Nearest to ['if']: under, high, year, law, both, part, information, game, like, much, Median sim: 0.988\n",
            "Nearest to ['over']: after, i, used, about, within, because, see, states, new, into, Median sim: 0.988\n",
            "Nearest to ['when']: who, they, at, an, been, would, eight, or, use, as, Median sim: 0.949\n",
            "Nearest to ['x']: before, life, game, several, government, information, usually, man, way, modern, Median sim: 0.987\n",
            "Nearest to ['time']: there, first, between, had, american, other, into, some, about, has, Median sim: 0.988\n",
            "Nearest to ['since']: usually, number, states, another, order, after, will, much, people, what, Median sim: 0.987\n",
            "Nearest to ['will']: law, several, between, after, small, another, external, countries, those, new, Median sim: 0.987\n",
            "[2018-10-30 04:52:26,501]INFO:root:Epoch: 0, Iteration 3123200, loss=0.03233013\n",
            "[2018-10-30 04:52:30,103]INFO:root:Epoch: 0, Iteration 3174400, loss=0.0011164089\n",
            "[2018-10-30 04:52:33,593]INFO:root:Epoch: 0, Iteration 3225600, loss=0.029688967\n",
            "[2018-10-30 04:52:36,885]INFO:root:Epoch: 0, Iteration 3276800, loss=0.0033611688\n",
            "[2018-10-30 04:52:40,424]INFO:root:Epoch: 0, Iteration 3328000, loss=0.12529542\n",
            "[2018-10-30 04:52:43,960]INFO:root:Epoch: 0, Iteration 3379200, loss=0.0011680196\n",
            "[2018-10-30 04:52:47,270]INFO:root:Epoch: 0, Iteration 3430400, loss=0.0014217768\n",
            "[2018-10-30 04:52:50,433]INFO:root:Epoch: 0, Iteration 3481600, loss=0.12552477\n",
            "[2018-10-30 04:52:53,513]INFO:root:Epoch: 0, Iteration 3532800, loss=0.2497741\n",
            "[2018-10-30 04:52:56,609]INFO:root:Epoch: 0, Iteration 3584000, loss=0.0018675582\n",
            "[2018-10-30 04:52:59,754]INFO:root:Epoch: 0, Iteration 3635200, loss=0.0009908099\n",
            "[2018-10-30 04:53:02,873]INFO:root:Epoch: 0, Iteration 3686400, loss=0.001566722\n",
            "[2018-10-30 04:53:06,015]INFO:root:Epoch: 0, Iteration 3737600, loss=0.00038300734\n",
            "[2018-10-30 04:53:09,153]INFO:root:Epoch: 0, Iteration 3788800, loss=0.028058734\n",
            "[2018-10-30 04:53:12,296]INFO:root:Epoch: 0, Iteration 3840000, loss=0.12518676\n",
            "[2018-10-30 04:53:15,375]INFO:root:Epoch: 0, Iteration 3891200, loss=0.0010974862\n",
            "[2018-10-30 04:53:18,468]INFO:root:Epoch: 0, Iteration 3942400, loss=0.0010653281\n",
            "[2018-10-30 04:53:21,589]INFO:root:Epoch: 0, Iteration 3993600, loss=0.0021402235\n",
            "[2018-10-30 04:53:24,682]INFO:root:Epoch: 0, Iteration 4044800, loss=0.0030987612\n",
            "[2018-10-30 04:53:27,762]INFO:root:Epoch: 0, Iteration 4096000, loss=0.0011863976\n",
            "[2018-10-30 04:53:27,876]INFO:root:\n",
            "Nearest to ['english']: known, another, m, century, over, i, since, up, people, within, Median sim: 0.991\n",
            "Nearest to ['under']: several, list, still, man, language, those, if, work, around, into, Median sim: 0.993\n",
            "Nearest to ['some']: there, first, had, new, can, other, has, its, time, were, Median sim: 0.992\n",
            "Nearest to ['were']: first, there, american, other, new, most, can, some, has, had, Median sim: 0.992\n",
            "Nearest to ['united']: where, over, those, music, him, name, if, you, countries, into, Median sim: 0.992\n",
            "Nearest to ['e']: area, using, high, old, population, long, power, series, man, study, Median sim: 0.992\n",
            "Nearest to ['be']: s, are, on, from, seven, he, it, this, five, three, Median sim: 0.993\n",
            "Nearest to ['his']: he, not, it, which, s, are, from, also, this, three, Median sim: 0.992\n",
            "Nearest to ['b']: though, different, prime, however, flying, such, right, land, above, computers, Median sim: 0.978\n",
            "Nearest to ['if']: under, law, part, high, both, like, much, into, game, national, Median sim: 0.992\n",
            "Nearest to ['over']: after, because, i, number, about, within, into, law, states, several, Median sim: 0.993\n",
            "Nearest to ['when']: who, an, would, at, eight, been, they, or, use, that, Median sim: 0.97\n",
            "Nearest to ['x']: before, several, modern, man, now, us, name, still, part, film, Median sim: 0.992\n",
            "Nearest to ['time']: there, had, american, between, some, first, other, about, its, them, Median sim: 0.992\n",
            "Nearest to ['since']: after, states, i, number, over, between, another, people, where, will, Median sim: 0.992\n",
            "Nearest to ['will']: several, law, those, under, another, still, between, do, after, where, Median sim: 0.992\n",
            "[2018-10-30 04:53:30,970]INFO:root:Epoch: 0, Iteration 4147200, loss=0.00021804299\n",
            "[2018-10-30 04:53:34,049]INFO:root:Epoch: 0, Iteration 4198400, loss=0.0030830125\n",
            "[2018-10-30 04:53:37,200]INFO:root:Epoch: 0, Iteration 4249600, loss=0.00043840616\n",
            "[2018-10-30 04:53:40,303]INFO:root:Epoch: 0, Iteration 4300800, loss=0.0019783266\n",
            "[2018-10-30 04:53:43,374]INFO:root:Epoch: 0, Iteration 4352000, loss=0.14294817\n",
            "[2018-10-30 04:53:46,464]INFO:root:Epoch: 0, Iteration 4403200, loss=0.002886927\n",
            "[2018-10-30 04:53:49,630]INFO:root:Epoch: 0, Iteration 4454400, loss=0.00847368\n",
            "[2018-10-30 04:53:52,724]INFO:root:Epoch: 0, Iteration 4505600, loss=0.008807252\n",
            "[2018-10-30 04:53:55,847]INFO:root:Epoch: 0, Iteration 4556800, loss=0.0015641396\n",
            "[2018-10-30 04:53:59,021]INFO:root:Epoch: 0, Iteration 4608000, loss=0.01963218\n",
            "[2018-10-30 04:54:02,177]INFO:root:Epoch: 0, Iteration 4659200, loss=0.00019537538\n",
            "[2018-10-30 04:54:05,446]INFO:root:Epoch: 0, Iteration 4710400, loss=0.00069717463\n",
            "[2018-10-30 04:54:08,634]INFO:root:Epoch: 0, Iteration 4761600, loss=0.1254379\n",
            "[2018-10-30 04:54:11,886]INFO:root:Epoch: 0, Iteration 4812800, loss=0.15102592\n",
            "[2018-10-30 04:54:15,009]INFO:root:Epoch: 0, Iteration 4864000, loss=0.00078561954\n",
            "[2018-10-30 04:54:18,159]INFO:root:Epoch: 0, Iteration 4915200, loss=0.021070454\n",
            "[2018-10-30 04:54:21,273]INFO:root:Epoch: 0, Iteration 4966400, loss=0.0009118605\n",
            "[2018-10-30 04:54:24,439]INFO:root:Epoch: 0, Iteration 5017600, loss=0.002795699\n",
            "[2018-10-30 04:54:27,577]INFO:root:Epoch: 0, Iteration 5068800, loss=0.0005383609\n",
            "[2018-10-30 04:54:30,764]INFO:root:Epoch: 0, Iteration 5120000, loss=0.0012014817\n",
            "[2018-10-30 04:54:30,881]INFO:root:\n",
            "Nearest to ['english']: another, since, m, x, century, people, known, no, within, up, Median sim: 0.994\n",
            "Nearest to ['under']: list, several, man, if, work, language, still, those, around, long, Median sim: 0.995\n",
            "Nearest to ['some']: there, first, had, new, can, other, has, time, all, its, Median sim: 0.995\n",
            "Nearest to ['were']: first, there, other, can, has, have, most, new, some, had, Median sim: 0.994\n",
            "Nearest to ['united']: name, those, music, him, where, union, french, if, number, countries, Median sim: 0.995\n",
            "Nearest to ['e']: high, using, area, series, long, power, population, old, list, man, Median sim: 0.995\n",
            "Nearest to ['be']: s, are, from, on, he, it, this, which, not, his, Median sim: 0.995\n",
            "Nearest to ['his']: he, not, are, it, which, s, from, this, also, be, Median sim: 0.994\n",
            "Nearest to ['b']: though, different, however, such, prime, right, land, flying, above, done, Median sim: 0.985\n",
            "Nearest to ['if']: part, both, under, law, year, like, game, high, much, government, Median sim: 0.995\n",
            "Nearest to ['over']: after, because, used, states, into, i, number, about, several, government, Median sim: 0.995\n",
            "Nearest to ['when']: would, at, they, been, an, who, or, eight, that, as, Median sim: 0.98\n",
            "Nearest to ['x']: before, several, government, life, name, modern, game, part, usually, man, Median sim: 0.995\n",
            "Nearest to ['time']: there, had, american, first, some, more, other, new, between, into, Median sim: 0.995\n",
            "Nearest to ['since']: states, another, number, people, between, will, after, over, much, usually, Median sim: 0.995\n",
            "Nearest to ['will']: several, law, between, another, those, where, under, very, since, people, Median sim: 0.995\n",
            "[2018-10-30 04:54:33,999]INFO:root:Epoch: 0, Iteration 5171200, loss=0.12546282\n",
            "[2018-10-30 04:54:37,121]INFO:root:Epoch: 0, Iteration 5222400, loss=0.0013134473\n",
            "[2018-10-30 04:54:40,254]INFO:root:Epoch: 0, Iteration 5273600, loss=0.00044955395\n",
            "[2018-10-30 04:54:43,354]INFO:root:Epoch: 0, Iteration 5324800, loss=0.0011819599\n",
            "[2018-10-30 04:54:46,492]INFO:root:Epoch: 0, Iteration 5376000, loss=0.064868286\n",
            "[2018-10-30 04:54:49,614]INFO:root:Epoch: 0, Iteration 5427200, loss=0.0016406194\n",
            "[2018-10-30 04:54:52,727]INFO:root:Epoch: 0, Iteration 5478400, loss=0.0028903368\n",
            "[2018-10-30 04:54:55,942]INFO:root:Epoch: 0, Iteration 5529600, loss=0.001887048\n",
            "[2018-10-30 04:54:59,143]INFO:root:Epoch: 0, Iteration 5580800, loss=0.08956305\n",
            "[2018-10-30 04:55:02,313]INFO:root:Epoch: 0, Iteration 5632000, loss=0.0033360275\n",
            "[2018-10-30 04:55:05,518]INFO:root:Epoch: 0, Iteration 5683200, loss=0.24935938\n",
            "[2018-10-30 04:55:08,667]INFO:root:Epoch: 0, Iteration 5734400, loss=0.00086087815\n",
            "[2018-10-30 04:55:11,855]INFO:root:Epoch: 0, Iteration 5785600, loss=0.12581132\n",
            "[2018-10-30 04:55:15,060]INFO:root:Epoch: 0, Iteration 5836800, loss=0.0027760146\n",
            "[2018-10-30 04:55:18,253]INFO:root:Epoch: 0, Iteration 5888000, loss=0.002765866\n",
            "[2018-10-30 04:55:21,468]INFO:root:Epoch: 0, Iteration 5939200, loss=0.00034595496\n",
            "[2018-10-30 04:55:24,685]INFO:root:Epoch: 0, Iteration 5990400, loss=0.124939255\n",
            "[2018-10-30 04:55:27,856]INFO:root:Epoch: 0, Iteration 6041600, loss=0.15762272\n",
            "[2018-10-30 04:55:31,057]INFO:root:Epoch: 0, Iteration 6092800, loss=0.00048206962\n",
            "[2018-10-30 04:55:34,421]INFO:root:Epoch: 0, Iteration 6144000, loss=0.0011351029\n",
            "[2018-10-30 04:55:34,545]INFO:root:\n",
            "Nearest to ['english']: another, x, since, known, up, people, m, no, like, within, Median sim: 0.996\n",
            "Nearest to ['under']: still, list, several, man, work, those, language, around, power, part, Median sim: 0.997\n",
            "Nearest to ['some']: there, first, had, new, can, other, its, all, their, were, Median sim: 0.996\n",
            "Nearest to ['were']: first, there, other, had, can, new, some, but, most, has, Median sim: 0.996\n",
            "Nearest to ['united']: name, where, music, those, him, union, over, number, countries, french, Median sim: 0.996\n",
            "Nearest to ['e']: high, area, using, series, power, population, old, long, own, british, Median sim: 0.996\n",
            "Nearest to ['be']: are, s, from, he, it, on, this, his, not, which, Median sim: 0.996\n",
            "Nearest to ['his']: he, not, are, which, it, this, be, from, s, also, Median sim: 0.996\n",
            "Nearest to ['b']: though, different, however, prime, such, right, land, above, flying, done, Median sim: 0.99\n",
            "Nearest to ['if']: both, part, law, under, where, year, government, like, him, national, Median sim: 0.996\n",
            "Nearest to ['over']: because, law, about, number, both, government, states, into, several, i, Median sim: 0.996\n",
            "Nearest to ['when']: they, would, who, at, an, been, or, use, eight, that, Median sim: 0.986\n",
            "Nearest to ['x']: before, life, several, name, government, game, part, modern, man, film, Median sim: 0.996\n",
            "Nearest to ['time']: american, between, there, into, more, had, about, than, after, years, Median sim: 0.996\n",
            "Nearest to ['since']: states, another, number, people, will, over, where, between, part, name, Median sim: 0.996\n",
            "Nearest to ['will']: law, several, between, where, since, another, people, very, system, no, Median sim: 0.996\n",
            "[2018-10-30 04:55:37,722]INFO:root:Epoch: 0, Iteration 6195200, loss=0.00013354665\n",
            "[2018-10-30 04:55:40,906]INFO:root:Epoch: 0, Iteration 6246400, loss=0.029406046\n",
            "[2018-10-30 04:55:44,122]INFO:root:Epoch: 0, Iteration 6297600, loss=0.00032402866\n",
            "[2018-10-30 04:55:47,310]INFO:root:Epoch: 0, Iteration 6348800, loss=0.12568443\n",
            "[2018-10-30 04:55:50,640]INFO:root:Epoch: 0, Iteration 6400000, loss=0.0016555007\n",
            "[2018-10-30 04:55:53,795]INFO:root:Epoch: 0, Iteration 6451200, loss=0.00038934487\n",
            "[2018-10-30 04:55:56,976]INFO:root:Epoch: 0, Iteration 6502400, loss=0.1274152\n",
            "[2018-10-30 04:56:00,177]INFO:root:Epoch: 0, Iteration 6553600, loss=0.0012169634\n",
            "[2018-10-30 04:56:03,416]INFO:root:Epoch: 0, Iteration 6604800, loss=0.00033781835\n",
            "[2018-10-30 04:56:06,633]INFO:root:Epoch: 0, Iteration 6656000, loss=0.03565856\n",
            "[2018-10-30 04:56:09,845]INFO:root:Epoch: 0, Iteration 6707200, loss=0.0022798162\n",
            "[2018-10-30 04:56:13,046]INFO:root:Epoch: 0, Iteration 6758400, loss=0.020067258\n",
            "[2018-10-30 04:56:16,262]INFO:root:Epoch: 0, Iteration 6809600, loss=0.25159058\n",
            "[2018-10-30 04:56:19,462]INFO:root:Epoch: 0, Iteration 6860800, loss=0.00037453204\n",
            "[2018-10-30 04:56:22,649]INFO:root:Epoch: 0, Iteration 6912000, loss=0.0015698837\n",
            "[2018-10-30 04:56:25,835]INFO:root:Epoch: 0, Iteration 6963200, loss=0.015802372\n",
            "[2018-10-30 04:56:29,026]INFO:root:Epoch: 0, Iteration 7014400, loss=0.12738308\n",
            "[2018-10-30 04:56:32,235]INFO:root:Epoch: 0, Iteration 7065600, loss=0.0062714396\n",
            "[2018-10-30 04:56:35,441]INFO:root:Epoch: 0, Iteration 7116800, loss=0.016074235\n",
            "[2018-10-30 04:56:38,631]INFO:root:Epoch: 0, Iteration 7168000, loss=0.066904604\n",
            "[2018-10-30 04:56:38,752]INFO:root:\n",
            "Nearest to ['english']: another, known, century, no, since, x, up, m, people, name, Median sim: 0.997\n",
            "Nearest to ['under']: several, list, man, language, if, those, work, still, part, being, Median sim: 0.997\n",
            "Nearest to ['some']: there, new, can, first, other, all, its, had, time, were, Median sim: 0.997\n",
            "Nearest to ['were']: first, there, other, have, can, some, had, but, new, most, Median sim: 0.997\n",
            "Nearest to ['united']: name, those, music, him, union, countries, if, number, she, no, Median sim: 0.997\n",
            "Nearest to ['e']: using, area, high, long, power, series, population, own, man, several, Median sim: 0.997\n",
            "Nearest to ['be']: are, s, from, on, it, this, he, which, his, not, Median sim: 0.997\n",
            "Nearest to ['his']: he, not, are, it, this, which, from, s, be, also, Median sim: 0.997\n",
            "Nearest to ['b']: though, different, however, prime, such, right, land, above, flying, done, Median sim: 0.992\n",
            "Nearest to ['if']: both, part, under, law, year, much, government, him, like, national, Median sim: 0.997\n",
            "Nearest to ['over']: because, number, about, after, i, government, both, states, law, often, Median sim: 0.997\n",
            "Nearest to ['when']: they, would, who, been, an, at, use, or, eight, that, Median sim: 0.988\n",
            "Nearest to ['x']: before, life, government, several, name, game, part, modern, law, language, Median sim: 0.997\n",
            "Nearest to ['time']: there, american, into, some, between, new, after, than, all, first, Median sim: 0.997\n",
            "Nearest to ['since']: states, number, another, people, will, over, between, i, name, because, Median sim: 0.997\n",
            "Nearest to ['will']: law, between, since, system, another, where, people, several, under, state, Median sim: 0.997\n",
            "[2018-10-30 04:56:41,965]INFO:root:Epoch: 0, Iteration 7219200, loss=0.12479785\n",
            "[2018-10-30 04:56:45,180]INFO:root:Epoch: 0, Iteration 7270400, loss=0.00091884786\n",
            "[2018-10-30 04:56:48,550]INFO:root:Epoch: 0, Iteration 7321600, loss=0.00086128485\n",
            "[2018-10-30 04:56:51,905]INFO:root:Epoch: 0, Iteration 7372800, loss=0.00031471957\n",
            "[2018-10-30 04:56:55,183]INFO:root:Epoch: 0, Iteration 7424000, loss=0.057881158\n",
            "[2018-10-30 04:56:58,498]INFO:root:Epoch: 0, Iteration 7475200, loss=0.0003251778\n",
            "[2018-10-30 04:57:01,732]INFO:root:Epoch: 0, Iteration 7526400, loss=0.00041508191\n",
            "[2018-10-30 04:57:04,953]INFO:root:Epoch: 0, Iteration 7577600, loss=0.1248153\n",
            "[2018-10-30 04:57:08,271]INFO:root:Epoch: 0, Iteration 7628800, loss=0.0004411146\n",
            "[2018-10-30 04:57:11,597]INFO:root:Epoch: 0, Iteration 7680000, loss=0.00012183766\n",
            "[2018-10-30 04:57:14,707]INFO:root:Epoch: 0, Iteration 7731200, loss=0.0015099844\n",
            "[2018-10-30 04:57:17,834]INFO:root:Epoch: 0, Iteration 7782400, loss=0.00012450262\n",
            "[2018-10-30 04:57:20,965]INFO:root:Epoch: 0, Iteration 7833600, loss=0.1566866\n",
            "[2018-10-30 04:57:24,128]INFO:root:Epoch: 0, Iteration 7884800, loss=0.0002853658\n",
            "[2018-10-30 04:57:27,260]INFO:root:Epoch: 0, Iteration 7936000, loss=0.001232581\n",
            "[2018-10-30 04:57:30,417]INFO:root:Epoch: 0, Iteration 7987200, loss=0.005991983\n",
            "[2018-10-30 04:57:33,604]INFO:root:Epoch: 0, Iteration 8038400, loss=0.03697614\n",
            "[2018-10-30 04:57:36,780]INFO:root:Epoch: 0, Iteration 8089600, loss=0.004751283\n",
            "[2018-10-30 04:57:39,928]INFO:root:Epoch: 0, Iteration 8140800, loss=0.00038285617\n",
            "[2018-10-30 04:57:43,100]INFO:root:Epoch: 0, Iteration 8192000, loss=0.0001854936\n",
            "[2018-10-30 04:57:43,214]INFO:root:\n",
            "Nearest to ['english']: another, x, no, m, century, within, known, name, number, like, Median sim: 0.997\n",
            "Nearest to ['under']: several, man, list, language, still, if, work, those, part, being, Median sim: 0.998\n",
            "Nearest to ['some']: first, new, there, can, all, other, had, its, their, were, Median sim: 0.998\n",
            "Nearest to ['were']: first, there, other, can, have, had, some, new, has, most, Median sim: 0.997\n",
            "Nearest to ['united']: those, name, music, french, union, you, him, countries, number, if, Median sim: 0.998\n",
            "Nearest to ['e']: high, area, using, series, man, power, long, list, several, another, Median sim: 0.998\n",
            "Nearest to ['be']: s, are, from, it, this, on, he, his, which, not, Median sim: 0.997\n",
            "Nearest to ['his']: he, not, this, are, it, from, which, s, be, three, Median sim: 0.997\n",
            "Nearest to ['b']: though, different, however, such, prime, right, land, above, flying, done, Median sim: 0.993\n",
            "Nearest to ['if']: both, part, under, law, much, government, year, th, early, national, Median sim: 0.998\n",
            "Nearest to ['over']: because, number, after, both, government, about, i, often, into, states, Median sim: 0.998\n",
            "Nearest to ['when']: they, would, who, been, an, at, use, or, eight, that, Median sim: 0.99\n",
            "Nearest to ['x']: before, life, several, name, game, part, government, modern, man, film, Median sim: 0.998\n",
            "Nearest to ['time']: american, into, between, after, some, about, there, than, all, first, Median sim: 0.997\n",
            "Nearest to ['since']: number, states, people, between, will, over, another, name, what, much, Median sim: 0.998\n",
            "Nearest to ['will']: between, since, where, system, people, state, law, several, another, after, Median sim: 0.998\n",
            "[2018-10-30 04:57:46,472]INFO:root:Epoch: 0, Iteration 8243200, loss=0.0004013772\n",
            "[2018-10-30 04:57:49,637]INFO:root:Epoch: 0, Iteration 8294400, loss=0.12642796\n",
            "[2018-10-30 04:57:52,839]INFO:root:Epoch: 0, Iteration 8345600, loss=0.0005059023\n",
            "[2018-10-30 04:57:56,017]INFO:root:Epoch: 0, Iteration 8396800, loss=0.025411356\n",
            "[2018-10-30 04:57:59,215]INFO:root:Epoch: 0, Iteration 8448000, loss=0.0011063487\n",
            "[2018-10-30 04:58:02,431]INFO:root:Epoch: 0, Iteration 8499200, loss=0.004144273\n",
            "[2018-10-30 04:58:05,637]INFO:root:Epoch: 0, Iteration 8550400, loss=0.00019573697\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}